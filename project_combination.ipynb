{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사람 정확도 뽑아내는 함수\n",
    "def person_acc(data):\n",
    "    if 'person: ' in data:\n",
    "        return int(data.split('person: ')[-1].split('%')[0]) # 이해 안가면 여쭤봐주세요\n",
    "    else: return 0\n",
    "\n",
    "# fps 뽑아내는 함수\n",
    "def fps(data):\n",
    "    return float(data.split('FPS:')[-1])\n",
    "\n",
    "    \n",
    "def parsing_log(log_dir, accuracy):\n",
    "    with open(log_dir, 'r') as f:\n",
    "        string=f.read()\n",
    "    \n",
    "    p=re.compile(r'\\n+')\n",
    "    cleaned_string = p.sub('', string)\n",
    "\n",
    "    cleaned_string = cleaned_string.replace('Stream closed. cvWriteFrame input video stream closed.  closing... closed!output_video_writer closed.', '')\n",
    "\n",
    "    content = cleaned_string.split(' cvWriteFrame Objects:')[1:] # 반복되는 단어 기준으로 스트링을 쪼갭니다.\n",
    "    # 0번이 아니라 1번부터 부르는 이유는 0번에 필요없는 문자가 들어가서\n",
    "\n",
    "    length = len(content)\n",
    "\n",
    "    # 쪼갠 내용을 데이터프레임으로 바꿈\n",
    "\n",
    "    df = pd.DataFrame(content)\n",
    "\n",
    "    df['acc'] = df[0].apply(person_acc)\n",
    "    df['fps'] = df[0].apply(fps)\n",
    "\n",
    "    # df.loc[df['acc']!=0, :] 이 코드로 잘 구분되었는지 확인 가능\n",
    "\n",
    "    # 행 추가(앞에 두개 뒤에 한개)\n",
    "    df.index= (range(2, length+2))\n",
    "    df.loc[0, :] = [0, 0, 0]\n",
    "    df.loc[1, :] = [0, 0, 0]\n",
    "    df.loc[length+2, :] = [0, 0, 0]\n",
    "    df = df.sort_index(axis=0)\n",
    "\n",
    "    return list((np.rint((df.loc[df['acc']>=accuracy, :].index).astype(float)/(1.25))).astype(int))\n",
    "\n",
    "# 특정 정확도 이상의 프레임 추출\n",
    "def frame_extracting_by_log(video_dir, log):\n",
    "    i= 0 # 파일 명의 인덱스를 만들어 주기 위한 변수\n",
    "    result = []\n",
    "    capture = cv2.VideoCapture(video_dir)\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        if log.count(i):\n",
    "            cv2.imwrite(f'result/result{i}.png', frame)\n",
    "            result.append(i)\n",
    "\n",
    "        if i != capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            i+=1\n",
    "\n",
    "        else : return result\n",
    "            \n",
    "def frame_extracting_by_color(video_dir) :\n",
    "    lower_purple = np.array([149,254,252]) # Min_range\n",
    "    upper_purple = np.array([150,255,255]) # Max_range\n",
    "    i= 0 # 파일 명의 인덱스를 만들어 주기 위한 변수\n",
    "    result = []\n",
    "    capture = cv2.VideoCapture(video_dir)\n",
    "    \n",
    "    while True :\n",
    "        ret, frame = capture.read() # 비디오 읽어오기\n",
    "            \n",
    "        img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # BGR 이미지를 HSV로 바꿈.\n",
    "        image_mask = cv2.inRange(img_hsv, lower_purple, upper_purple) # lower - upper 지정한 범위의 색이 있는지 확인하고, 나머지 부분을 모드 0으로 채움.\n",
    "        img_result = cv2.bitwise_and(frame, frame, mask = image_mask) # \n",
    "        \n",
    "        if img_result.sum() > np.zeros((img_result.shape)).sum() + 200000 : # 같은 것이 없다면, 그 모든 배열의 합은 0일 것이고 0이 아니라면 최소 하나의 색상이 있는것과 같다.\n",
    "            cv2.imwrite(f'result/result{i}.png', frame)\n",
    "            result.append(i)\n",
    "\n",
    "        if i != capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            i+=1\n",
    "\n",
    "        else : return result\n",
    "        \n",
    "def face_detect(result):\n",
    "    face_cascade = cv2.CascadeClassifier('./face_detect/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    image_list = [f'result/result{i}.png' for i in result]\n",
    "    imgNum = 0\n",
    "    \n",
    "    for image in image_list:\n",
    "        image=cv2.imread(image)\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(grayImage, 1.03, 5)\n",
    "             \n",
    "        if len(faces)!=0:\n",
    "              \n",
    "            for (x,y,w,h) in faces:\n",
    "                # cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cropped = image[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "                # 이미지를 저장\n",
    "                height, width, channel = cropped.shape\n",
    "                img_result = cv2.pyrUp(cropped, (8*width, 8*height), borderType=cv2.BORDER_DEFAULT)\n",
    "                cv2.imwrite(f\"face/face{imgNum}.png\", img_result) # cropped , img_result\n",
    "                imgNum += 1\n",
    "                \n",
    "def image_cropping(image, h1, h2, w1, w2):\n",
    "    return image[h1:h2, w1:w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_100 = parsing_log('data/test_det_log.txt', 100)\n",
    "\n",
    "result = frame_extracting_by_log('data/test_det.mp4', over_100)\n",
    "\n",
    "face_detect(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
